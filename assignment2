import sklearn
import sklearn.tree
import numpy as np
import graphviz
from StringIO import StringIO
from sklearn.naive_bayes import BernoulliNB

# Initiate classifier
infoGain_clf = sklearn.tree.DecisionTreeClassifier(criterion='entropy')
bayes_clf = BernoulliNB()
ss = StringIO()



def load_data():

    return np.genfromtxt('house-votes-84.data', dtype=None, delimiter=',')


def process(process_type, classifier_type):

    col_names = [
        'RepubOrDemo', 'handicapped-infants', 'water-project-cost-sharing', 'adoption-of-the-budget-resolution',
        'physician-fee-freeze', 'el-salvador-aid', 'religious-groups-in-schools', 'anti-satellite-test-ban',
        'aid-to-nicaraguan-contras', 'mx-missile', 'immigration', 'synfuels-corporation-cutback', 'education-spending',
        'superfund-right-to-sue', 'crime', 'duty-free-exports', 'export-administration-act-south-africa'
    ]

    my_votes_array = load_data()

    x_matrix1 = my_votes_array[:, 1:]
    x_matrix2 = my_votes_array

    feature_names = np.array(col_names[1:])

    label_name = ['Republican', 'Democrat']

    if process_type == 'ternary':
        x_matrix = ternary(x_matrix1)
        x_matrix = x_matrix.astype(int)
        y = my_votes_array[:, :1]
    else:
        x_matrix = skip(x_matrix2)
        y = x_matrix[:, :1]
        x_matrix = x_matrix[:, 1:]
        x_matrix = x_matrix.astype(int)

    # Fit classifier
    if classifier_type is 'decision':
        infoGain_clf.fit(x_matrix, y)
        sklearn.tree.export_graphviz(infoGain_clf.tree_, feature_names=feature_names,
                                     class_names=label_name,
                                     label="all", out_file=ss)

        graphviz.Source(ss.getvalue())
        get_tree_prediction(-2, x_matrix, y)
    else:
        bayes_clf.fit(x_matrix, y.ravel())
        get_bayes_prediction(-2, x_matrix, y)


def ternary(data):

    data[data == 'y'] = 1
    data[data == 'n'] = 0
    data[data == '?'] = 2

    return data


def skip(data):

    data[data == 'y'] = 1
    data[data == 'n'] = 0

    indices = np.where(data == '?')
    data = np.delete(data, list(set(indices[0])), 0)

    return data


def get_tree_prediction(row_num, data, y):
    print "predicted:", infoGain_clf.predict(data[row_num:, :])
    print "truth", y[row_num:]
    print '\n'


def get_bayes_prediction(row_num, data, y):
    print "predicted:", bayes_clf.predict(data[row_num:, :])
    print "truth", y[row_num:]
    print '\n'


def replace_cols_with_y_or_n(data):

    my_data = data

    for i in range(1, 17):

        yes_cols = np.where(my_data[:, i] == 'y')
        no_cols = np.where(my_data[:, i] == 'n')

        if len(yes_cols[0]) >= len(no_cols[0]):
            my_data[my_data[:, i] == '?', i] = 'y'
        elif len(yes_cols[0]) < len(no_cols[0]):
            my_data[my_data[:, i] == '?', i] = 'n'

    return my_data

# print 'DECISION::SKIP?::'
# process('skip', 'decision')
# print 'DECISION::TERNARY::'
# process('ternary', 'decision')
# print 'NAIVE_BAYES::TERNARY::'
# process('ternary', 'naive_bayes')
# print 'NAIVE_BAYES::SKIP::'
# process('skip', 'naive_bayes')



